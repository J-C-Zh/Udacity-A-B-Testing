{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# Udacity AB Testing Final Project\n\nThis is the final project for Udacity course A/B Testing."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 1. Experiment Overview: Free Trial Screener\n\nAt the time of this experiment, Udacity courses currently have two options on the course overview page: \"start free trial\", and \"access course materials\". If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n\n\nIn the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. This [screenshot](https://drive.google.com/file/d/0ByAfiG8HpNUMakVrS0s4cGN2TjQ/view) shows what the experiment looks like.\n\n\nThe hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time\u2014without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n\n\n__The unit of diversion is a cookie__, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page.\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 2. Experiment design\n\n### 2.1 Metric Choice"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Which of the following metrics would you choose to measure for this experiment and why? For each metric you choose, indicate whether you would use it as an invariant metric or an evaluation metric. The practical significance boundary for each metric, that is, the difference that would have to be observed before that was a meaningful change for the business, is given in parentheses. All practical significance boundaries are given as absolute changes.\n\n\nAny place \"unique cookies\" are mentioned, the uniqueness is determined by day. (That is, the same cookie visiting on different days would be counted twice.) User-ids are automatically unique since the site does not allow the same user-id to enroll twice.\n\n\n* Number of cookies: That is, number of unique cookies to view the course overview page. (dmin=3000)\n* Number of user-ids: That is, number of users who enroll in the free trial. (dmin=50)\n* Number of clicks: That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). (dmin=240)\n* Click-through-probability: That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. (dmin=0.01)\n* Gross conversion: That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. (dmin= 0.01)\n* Retention: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout. (dmin=0.01)\n* Net conversion: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. (dmin= 0.0075)"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 2.1.1 Invariant Metrics\n\n_Invariant metrics are the metrics that should not change across the control and experiment groups during the experiment._\n\n_* Number of cookies This is the unit of diversion. We expect the cookies are evenly distributed among control and experiment groups. Therefore, the number of cookies could be used as an invariant metric._\n\n_* Number of clicks Since the number of clicks that happens before the free trial screener is triggered, this should not change across control and experiment groups and can be used as an invariant metric._\n\n_* Click-through-probability At this point, the users haven't been affected by the pop-up page yet. We expect the CTP would not change at this stage and can be used as an invariant metric._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 2.1.2 Evaluation Metrics\n\n_Evaluation metrics are the metrics that are used to measure the difference across the control and experiment groups during the experiment._\n\n_* Gross conversion. This could be used as an evaluation metric. At this stage, the screener has already popped up. If there are any effects, we could see some change in gross conversion value._\n\n_* Retention. If there is an effect for the experiments group, then it is less likely that the students in the experiment group drop off the course after 14-days simply because they are failed to spend enough time per week on the course. Therefore retention will change and can be used as an evaluation metric._\n\n_* Net conversion. We expect to see those students who don't have enough time to leave before they enroll in the free trial in the experiment group. Those who do not have enough time in the control group may leave during a 14-day free trial and get frustrated. No matter when they decide to leave, the total number of students to remain enrolled past the 14-day trial should not change much for both groups. In other words, we expect there is no significantly reducing the number of students to continue past the free trial and eventually complete the course. With that said, the net conversion should not change significantly in our case._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2.2 Measuring Variability\nThis [spreadsheet](https://docs.google.com/spreadsheets/d/1MYNUtC47Pg8hdoCjOXaHqF-thheGpUshrFA21BAJnNc/edit#gid=0) contains rough estimates of the baseline values for these metrics (again, these numbers have been changed from Udacity's true numbers).\n\n\nFor each metric you selected as an evaluation metric, estimate its standard deviation analytically. Do you expect the analytic estimates to be accurate? That is, for which metrics, if any, would you want to collect an empirical estimate of the variability if you had time?"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='d6948de9-f1e9-45af-96ba-62adf20fe437', project_access_token='p-e04de4bdab58d2dcf36e62171a41997e85dff72f')\npc = project.project_context\n\nimport pandas as pd\n\ndef get_file_handle(fname):\n    # Project data path for the raw data file\n    data_path = project.get_file(fname)\n    data_path.seek(0)\n    return data_path\n\nDATA_PATH = 'Final Project Baseline Values.csv'\n\ndata_path = get_file_handle(DATA_PATH)\nbaseline_data = pd.read_csv(data_path,names = ['Baseline Values'])\n\n\nbaseline_data",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 2,
                    "data": {
                        "text/plain": "                                                    Baseline Values\nUnique cookies to view course overview page per...     40000.000000\nUnique cookies to click \"Start free trial\" per ...      3200.000000\nEnrollments per day:                                     660.000000\nClick-through-probability on \"Start free trial\":           0.080000\nProbability of enrolling, given click:                     0.206250\nProbability of payment, given enroll:                      0.530000\nProbability of payment, given click                        0.109313",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Baseline Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Unique cookies to view course overview page per day:</th>\n      <td>40000.000000</td>\n    </tr>\n    <tr>\n      <th>Unique cookies to click \"Start free trial\" per day:</th>\n      <td>3200.000000</td>\n    </tr>\n    <tr>\n      <th>Enrollments per day:</th>\n      <td>660.000000</td>\n    </tr>\n    <tr>\n      <th>Click-through-probability on \"Start free trial\":</th>\n      <td>0.080000</td>\n    </tr>\n    <tr>\n      <th>Probability of enrolling, given click:</th>\n      <td>0.206250</td>\n    </tr>\n    <tr>\n      <th>Probability of payment, given enroll:</th>\n      <td>0.530000</td>\n    </tr>\n    <tr>\n      <th>Probability of payment, given click</th>\n      <td>0.109313</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Given sample size of 5000 page views, add a column to refect corresponding cookies to click \"star free trail\" per day and enrollments per day.\n\nbaseline_data['Sample'] = 'NA'\n\nbaseline_data.loc['Unique cookies to view course overview page per day:','Sample'] = 5000\n\nbaseline_data.loc['Unique cookies to click \"Start free trial\" per day:','Sample'] = baseline_data.loc['Unique cookies to click \"Start free trial\" per day:','Baseline Values']/baseline_data.loc['Unique cookies to view course overview page per day:','Baseline Values']*baseline_data.loc['Unique cookies to view course overview page per day:','Sample']\n\nbaseline_data.loc['Enrollments per day:','Sample'] = baseline_data.loc['Enrollments per day:','Baseline Values']/baseline_data.loc['Unique cookies to view course overview page per day:','Baseline Values']*baseline_data.loc['Unique cookies to view course overview page per day:','Sample']\n\nbaseline_data\n",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 3,
                    "data": {
                        "text/plain": "                                                    Baseline Values Sample\nUnique cookies to view course overview page per...     40000.000000   5000\nUnique cookies to click \"Start free trial\" per ...      3200.000000    400\nEnrollments per day:                                     660.000000   82.5\nClick-through-probability on \"Start free trial\":           0.080000     NA\nProbability of enrolling, given click:                     0.206250     NA\nProbability of payment, given enroll:                      0.530000     NA\nProbability of payment, given click                        0.109313     NA",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Baseline Values</th>\n      <th>Sample</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Unique cookies to view course overview page per day:</th>\n      <td>40000.000000</td>\n      <td>5000</td>\n    </tr>\n    <tr>\n      <th>Unique cookies to click \"Start free trial\" per day:</th>\n      <td>3200.000000</td>\n      <td>400</td>\n    </tr>\n    <tr>\n      <th>Enrollments per day:</th>\n      <td>660.000000</td>\n      <td>82.5</td>\n    </tr>\n    <tr>\n      <th>Click-through-probability on \"Start free trial\":</th>\n      <td>0.080000</td>\n      <td>NA</td>\n    </tr>\n    <tr>\n      <th>Probability of enrolling, given click:</th>\n      <td>0.206250</td>\n      <td>NA</td>\n    </tr>\n    <tr>\n      <th>Probability of payment, given enroll:</th>\n      <td>0.530000</td>\n      <td>NA</td>\n    </tr>\n    <tr>\n      <th>Probability of payment, given click</th>\n      <td>0.109313</td>\n      <td>NA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import math\n# number of cookies to click \"Start free trial\" per day \nnumber_cookies = baseline_data.loc['Unique cookies to click \"Start free trial\" per day:','Sample']\n# number of user id who enroll in the free trial \nnumber_id_enroll = baseline_data.loc['Enrollments per day:','Sample'] \n\n# Standard deviation of Gross conversion\nSE_gc = math.sqrt(0.20625*(1-0.20625)/number_cookies)\n# Standard deviation for Retention\nSE_re = math.sqrt(0.53*(1-0.53)/number_id_enroll)\n# Standard deviation for net conversion\nSE_nc = math.sqrt(0.109313*(1-0.109313)/number_cookies)\n\nprint('The standard deviation for gross conversion is {}'.format(round(SE_gc,4)))\nprint('The standard deviation for retention is {}'.format(round(SE_re,4)))\nprint('The standard deviation for net conversion is {}'.format(round(SE_nc,4)))",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "The standard deviation for gross conversion is 0.0202\nThe standard deviation for retention is 0.0549\nThe standard deviation for net conversion is 0.0156\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "_I expect analytical variance and empirical variance are close for gross conversion and net conversion because the unit of analysis and unit of diversion are both number of cookies for those two metrics. But the analytical and empirical variances would not match for retention matric because the unit of analysis is the number of user IDs, and the unit of diversion is the number of cookies._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2.3 Sizing\n\n#### 2.3.1 Choosing Number of Samples given Power\nUsing the analytic estimates of variance, how many pageviews total (across both groups) would you need to collect to adequately power the experiment? Use an alpha of 0.05 and a beta of 0.2. Make sure you have enough power for each metric."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "_I do not plan to use bonferroni correction for this project because it is usually too convservative. I will use [online sample size calculator](https://www.evanmiller.org/ab-testing/sample-size.html) to do the calculation._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "_1. Gross conversion matric_\n     \n   _Given dmin = 0.01, baseline conversion rate = 0.206250, we will need 25,835 unique cookies to click the \"Start free trial\" button in each group. The total cookies to click the \"Start free trial\" button needed for both control and experiment groups are 25835*2 = 51670. Given baseline values that Unique cookies to click \"Start free trial\" per day/Unique cookies to view course overview page per day = 3,200/40,000 = 0.08. To get 51,670 cookies to click \"Start free trial\" button, we will need 51,670/0.08 = 645,875 pageviews._\n   \n_2. Retention matric_\n\n  _Given dmin = 0.01, baseline conversion rate = 0.53, we will need 39115 use-ids to completed checkout. The total user-ids that completed checkout for both groups should be 39115*2 = 78,230. Givien enrollments per day/Unique cookies to view course overview page per day = 660/40000 = 0.0165, we will need 78230/0.0165 = 4,741,213 pageviews._\n  \n_3 Net conversion matric_\n  \n  _Givn dmin = 0.075, baseline conversion rate = 0.1093125, we will need 27,413 unique cookies to click the \"Start free trial\" button. The total unique cookies to click the \"Start free trial\" button for both groups should be 27,413*2 = 54,826. Given baseline values that Unique cookies to click \"Start free trial\" per day/Unique cookies to view course overview page per day = 3,200/40,000 = 0.08, we will neeed 54,826/0.08 = 685,325 pageviews._\n  \n\n_We need at least 4,741,213 pageviews to adequately power the experiment if we decide to use all three matrics._\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 2.3.2 Choosing Duration vs. Exposure\n\nWhat percentage of Udacity's traffic would you divert to this experiment (assuming there were no other experiments you wanted to run simultaneously)? Is the change risky enough that you wouldn't want to run on all traffic?\n\n\nGiven the percentage you chose, how long would the experiment take to run, using the analytic estimates of variance? If the answer is longer than a few weeks, then this is unreasonably long, and you should reconsider an earlier decision.\n\n_If we use all three evaluation metrics, then we need at least 4,741,213 pageviews. Give baseline value of 40,000 pageviews per day, we will need 4,741,213/40,000 = 119 days with 100% traffic exposed. That would be too long and too expensive. To limit the experiment duration within a resonable range, we may left off retention matric, and use the gross conversion and net conversion as evaluation metrics. Then the pageview we will need is 685,325. That will take 685,325/40,000 = 18 days with 100% exposure. With 50% exposure, the duration will be 35 days._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 3. Experiment Analysis\n\nThe data for you to analyze is [here](https://docs.google.com/spreadsheets/d/1Mu5u9GrybDdska-ljPXyBjTpdZIUev_6i7t4LRDfXM8/edit#gid=0). This data contains the raw information needed to compute the above metrics, broken down day by day. Note that there are two sheets within the spreadsheet - one for the experiment group, and one for the control group.\n\n\nThe meaning of each column is:\n\nPageviews: Number of unique cookies to view the course overview page that day.\nClicks: Number of unique cookies to click the course overview page that day.\nEnrollments: Number of user-ids to enroll in the free trial that day.\nPayments: Number of user-ids who who enrolled on that day to remain enrolled for 14 days and thus make a payment. (Note that the date for this column is the start date, that is, the date of enrollment, rather than the date of the payment. The payment happened 14 days later. Because of this, the enrollments and payments are tracked for 14 fewer days than the other columns.)\n\n### 3.1 Sanity Checks\nStart by checking whether your invariant metrics are equivalent between the two groups. If the invariant metric is a simple count that should be randomly split between the 2 groups, you can use a binomial test as demonstrated in Lesson 5. Otherwise, you will need to construct a confidence interval for a difference in proportions using a similar strategy as in Lesson 1, then check whether the difference between group values falls within that confidence level.\n\n\nIf your sanity checks fail, look at the day by day data and see if you can offer any insight into what is causing the problem."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define filename\nDATA_PATH_control = 'Copy of Final Project Results - Control.csv'\nDATA_PATH_experiment = 'Copy of Final Project Results - Experiment.csv'\n\n\n# Using pandas to read the data \n# Since the `DATE` column consists date-time information, we use Pandas parse_dates keyword for easier data processing\ndata_path_control = get_file_handle(DATA_PATH_control)\ncontrol_data = pd.read_csv(data_path_control, parse_dates=['Date'])\n\ndata_path_experiment = get_file_handle(DATA_PATH_experiment)\nexperiment_data = pd.read_csv(data_path_experiment, parse_dates=['Date'])\n\nexperiment_data",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 5,
                    "data": {
                        "text/plain": "           Date  Pageviews  Clicks  Enrollments  Payments\n0   Sat, Oct 11       7716     686        105.0      34.0\n1   Sun, Oct 12       9288     785        116.0      91.0\n2   Mon, Oct 13      10480     884        145.0      79.0\n3   Tue, Oct 14       9867     827        138.0      92.0\n4   Wed, Oct 15       9793     832        140.0      94.0\n5   Thu, Oct 16       9500     788        129.0      61.0\n6   Fri, Oct 17       9088     780        127.0      44.0\n7   Sat, Oct 18       7664     652         94.0      62.0\n8   Sun, Oct 19       8434     697        120.0      77.0\n9   Mon, Oct 20      10496     860        153.0      98.0\n10  Tue, Oct 21      10551     864        143.0      71.0\n11  Wed, Oct 22       9737     801        128.0      70.0\n12  Thu, Oct 23       8176     642        122.0      68.0\n13  Fri, Oct 24       9402     697        194.0      94.0\n14  Sat, Oct 25       8669     669        127.0      81.0\n15  Sun, Oct 26       8881     693        153.0     101.0\n16  Mon, Oct 27       9655     771        213.0     119.0\n17  Tue, Oct 28       9396     736        162.0     120.0\n18  Wed, Oct 29       9262     727        201.0      96.0\n19  Thu, Oct 30       9308     728        207.0      67.0\n20  Fri, Oct 31       8715     722        182.0     123.0\n21   Sat, Nov 1       8448     695        142.0     100.0\n22   Sun, Nov 2       8836     724        182.0     103.0\n23   Mon, Nov 3       9359     789          NaN       NaN\n24   Tue, Nov 4       9427     743          NaN       NaN\n25   Wed, Nov 5       9633     808          NaN       NaN\n26   Thu, Nov 6       9842     831          NaN       NaN\n27   Fri, Nov 7       9272     767          NaN       NaN\n28   Sat, Nov 8       8969     760          NaN       NaN\n29   Sun, Nov 9       9697     850          NaN       NaN\n30  Mon, Nov 10      10445     851          NaN       NaN\n31  Tue, Nov 11       9931     831          NaN       NaN\n32  Wed, Nov 12      10042     802          NaN       NaN\n33  Thu, Nov 13       9721     829          NaN       NaN\n34  Fri, Nov 14       9304     770          NaN       NaN\n35  Sat, Nov 15       8668     724          NaN       NaN\n36  Sun, Nov 16       8988     710          NaN       NaN",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Pageviews</th>\n      <th>Clicks</th>\n      <th>Enrollments</th>\n      <th>Payments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sat, Oct 11</td>\n      <td>7716</td>\n      <td>686</td>\n      <td>105.0</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sun, Oct 12</td>\n      <td>9288</td>\n      <td>785</td>\n      <td>116.0</td>\n      <td>91.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mon, Oct 13</td>\n      <td>10480</td>\n      <td>884</td>\n      <td>145.0</td>\n      <td>79.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tue, Oct 14</td>\n      <td>9867</td>\n      <td>827</td>\n      <td>138.0</td>\n      <td>92.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wed, Oct 15</td>\n      <td>9793</td>\n      <td>832</td>\n      <td>140.0</td>\n      <td>94.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Thu, Oct 16</td>\n      <td>9500</td>\n      <td>788</td>\n      <td>129.0</td>\n      <td>61.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Fri, Oct 17</td>\n      <td>9088</td>\n      <td>780</td>\n      <td>127.0</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sat, Oct 18</td>\n      <td>7664</td>\n      <td>652</td>\n      <td>94.0</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sun, Oct 19</td>\n      <td>8434</td>\n      <td>697</td>\n      <td>120.0</td>\n      <td>77.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Mon, Oct 20</td>\n      <td>10496</td>\n      <td>860</td>\n      <td>153.0</td>\n      <td>98.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Tue, Oct 21</td>\n      <td>10551</td>\n      <td>864</td>\n      <td>143.0</td>\n      <td>71.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Wed, Oct 22</td>\n      <td>9737</td>\n      <td>801</td>\n      <td>128.0</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Thu, Oct 23</td>\n      <td>8176</td>\n      <td>642</td>\n      <td>122.0</td>\n      <td>68.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Fri, Oct 24</td>\n      <td>9402</td>\n      <td>697</td>\n      <td>194.0</td>\n      <td>94.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sat, Oct 25</td>\n      <td>8669</td>\n      <td>669</td>\n      <td>127.0</td>\n      <td>81.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Sun, Oct 26</td>\n      <td>8881</td>\n      <td>693</td>\n      <td>153.0</td>\n      <td>101.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Mon, Oct 27</td>\n      <td>9655</td>\n      <td>771</td>\n      <td>213.0</td>\n      <td>119.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Tue, Oct 28</td>\n      <td>9396</td>\n      <td>736</td>\n      <td>162.0</td>\n      <td>120.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Wed, Oct 29</td>\n      <td>9262</td>\n      <td>727</td>\n      <td>201.0</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Thu, Oct 30</td>\n      <td>9308</td>\n      <td>728</td>\n      <td>207.0</td>\n      <td>67.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Fri, Oct 31</td>\n      <td>8715</td>\n      <td>722</td>\n      <td>182.0</td>\n      <td>123.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Sat, Nov 1</td>\n      <td>8448</td>\n      <td>695</td>\n      <td>142.0</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Sun, Nov 2</td>\n      <td>8836</td>\n      <td>724</td>\n      <td>182.0</td>\n      <td>103.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Mon, Nov 3</td>\n      <td>9359</td>\n      <td>789</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Tue, Nov 4</td>\n      <td>9427</td>\n      <td>743</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Wed, Nov 5</td>\n      <td>9633</td>\n      <td>808</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Thu, Nov 6</td>\n      <td>9842</td>\n      <td>831</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Fri, Nov 7</td>\n      <td>9272</td>\n      <td>767</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Sat, Nov 8</td>\n      <td>8969</td>\n      <td>760</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Sun, Nov 9</td>\n      <td>9697</td>\n      <td>850</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Mon, Nov 10</td>\n      <td>10445</td>\n      <td>851</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Tue, Nov 11</td>\n      <td>9931</td>\n      <td>831</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Wed, Nov 12</td>\n      <td>10042</td>\n      <td>802</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Thu, Nov 13</td>\n      <td>9721</td>\n      <td>829</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Fri, Nov 14</td>\n      <td>9304</td>\n      <td>770</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Sat, Nov 15</td>\n      <td>8668</td>\n      <td>724</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Sun, Nov 16</td>\n      <td>8988</td>\n      <td>710</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Sanity check for pageviews (metric #1)\n\n#To do sanity check, we will need to know the total pageviews for control and experiment groups.\npageviews_con = control_data['Pageviews'].sum()\npageviews_exp = experiment_data['Pageviews'].sum()\n\n# Calculate SE of pageviews. If the data for two groups are equally distrituted, then the probability that the data is assigned in one of the group is 0.5\n\nSE_pageviews = math.sqrt(0.5*(1-0.5)*(1/(pageviews_con+pageviews_exp)))\n\n# margin of error at confidence level of 95%\n\nME_pageviews = 1.96* SE_pageviews\n\nprint(\"The confidence interval (pageviews) ({},{})\".format(0.5-ME_pageviews,0.5+ME_pageviews))\n\nprint(\"The observed value (pageviews) {}\".format(pageviews_con/(pageviews_con+pageviews_exp)))",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Confidence interval (pageviews) (0.49882039214902313,0.5011796078509769)\nThe observed value (pageviews) 0.5006396668806133\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Sanity check for number of clicks (metric #3)\n\n#To do sanity check, we will need to know the total clicks for control and experiment groups.\nclicks_con = control_data['Clicks'].sum()\nclicks_exp = experiment_data['Clicks'].sum()\n\n# Calculate SE of pageviews. If the data for two groups are equally distrituted, then the probability that the data is assigned in one of the group is 0.5\n\nSE_clicks = math.sqrt(0.5*(1-0.5)*(1/(clicks_con+clicks_exp)))\n\n# margin of error at confidence level of 95%\n\nME_clicks = 1.96* SE_clicks\n\nprint(\"The confidence interval (clicks) ({},{})\".format(0.5-ME_clicks,0.5+ME_clicks))\n\nprint(\"The observed value (clicks) {}\".format(clicks_con/(clicks_con+clicks_exp)))",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Confidence interval (clicks) (0.49588449572378945,0.5041155042762105)\nThe observed value (clicks) 0.5004673474066628\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Sanity check for click-through-probability (metric #4)\n\n#To do sanity check, we will need to know the pooled probablity\np_pooled = (clicks_con+clicks_exp)/(pageviews_con+pageviews_exp)\n\n\n# Calculate SE of pageviews. If the data for two groups are equally distrituted, then the probability that the data is assigned in one of the group is 0.5\n\nSE_ctp = math.sqrt(p_pooled*(1-p_pooled)*(1/pageviews_con+1/pageviews_exp))\n\n# margin of error at confidence level of 95%\n\nME_ctp = 1.96* SE_ctp\n\nd = clicks_exp/pageviews_exp-clicks_con/pageviews_con\n\nprint(\"The confidence interval (CTP difference) ({},{})\".format(-ME_ctp,ME_ctp))\n\nprint(\"The observed value (CTP difference) {}\".format(d))\n",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Confidence interval (CTP difference) (-0.0012956791986518956,0.0012956791986518956)\nThe observed value (CTP difference) 5.662709158693602e-05\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "_All three invariant metrics passed sanity check._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3.2 Result Analysis\n\n#### 3.2.1 Effect Size Tests\n\n\nNext, for your evaluation metrics, calculate a confidence interval for the difference between the experiment and control groups, and check whether each metric is statistically and/or practically significance. A metric is statistically significant if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is practically significant if the confidence interval does not include the practical significance boundary (that is, you can be confident there is a change that matters to the business.)\n\n\nIf you have chosen multiple evaluation metrics, you will need to decide whether to use the Bonferroni correction. When deciding, keep in mind the results you are looking for in order to launch the experiment. Will the fact that you have multiple metrics make those results more likely to occur by chance than the alpha level of 0.05?\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Gross conversion: number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. (dmin= 0.01)\n\nenroll_con = control_data.loc[0:22,'Enrollments'].sum()\nenroll_exp = experiment_data.loc[0:22,'Enrollments'].sum()\nclicks_con_slice = control_data.loc[0:22,'Clicks'].sum()\nclicks_exp_slice = experiment_data.loc[0:22,'Clicks'].sum()\n\np_pooled_gc = (enroll_con+enroll_exp)/(clicks_con_slice+clicks_exp_slice)\nSE_gc = math.sqrt(p_pooled_gc*(1-p_pooled_gc)*(1/clicks_con_slice+1/clicks_exp_slice))\nME_gc = 1.96*SE_gc\nd_gc =enroll_exp/clicks_exp_slice-enroll_con/clicks_con_slice\n\nprint(\"The confidence interval for Gross conversion difference is ({},{})\".format(d_gc-ME_gc,d_gc+ME_gc))\nprint(\"d difference is {}\".format(d_gc))",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Confidence interval for Gross conversion difference is (-0.0291233583354044,-0.01198639082531873)\nd difference is -0.020554874580361565\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Net conversion: number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. (dmin= 0.0075)\n\npayments_con = control_data.loc[0:22,'Payments'].sum()\npayments_exp = experiment_data.loc[0:22,'Payments'].sum()\n\np_pooled_nc = (payments_con+payments_exp)/(clicks_con_slice+clicks_exp_slice)\nSE_nc = math.sqrt(p_pooled_nc*(1-p_pooled_nc)*(1/clicks_con_slice+1/clicks_exp_slice))\nME_nc = 1.96*SE_nc\nd_nc = payments_exp/clicks_exp_slice-payments_con/clicks_con_slice\n\nprint(\"The confidence interval for Net conversion difference is ({},{})\".format(d_nc-ME_nc,d_nc+ME_nc))\nprint(\"d difference is {}\".format(d_nc))",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Confidence interval for Net conversion difference is (-0.011604624359891718,0.001857179010803383)\nd difference is -0.0048737226745441675\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "_Gross conversion metric: \nThe confidence interval doesn't include zero or practical significance boundary. This metric is both statistically significant and practically significant._\n\n_Net conversion metric: \nThe confidence interval includes zero and practical significance boundary. This metric is neither statistically significant nor practically significant._\n\n_I didn't use Bonferroni correction. The Bonferroni correction can be conservative if there are a large number of tests and/or the test statistics are positively correlated[1](https://en.wikipedia.org/wiki/Bonferroni_correction). We expect our metrics to be correlated. The Bonferroni could be too conservative for our case. If we choose to use the Bonferroni correction, the alpha would be 0.025, which will make our results more likely to happen by chance._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 3.2.2 Sign Tests\n\nFor each evaluation metric, do a sign test using the day-by-day breakdown. If the sign test does not agree with the confidence interval for the difference, see if you can figure out why."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Gross conversion\n\ncontrol_data['Gross conversion'] = control_data['Enrollments']/control_data['Clicks']\ncontrol_data['Net conversion'] = control_data['Payments']/control_data['Clicks']\n\nexperiment_data['Gross conversion'] = experiment_data['Enrollments']/experiment_data['Clicks']\nexperiment_data['Net conversion'] = experiment_data['Payments']/experiment_data['Clicks']\n\nexperiment_data",
            "execution_count": 51,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 51,
                    "data": {
                        "text/plain": "           Date  Pageviews  Clicks  Enrollments  Payments  Gross conversion  \\\n0   Sat, Oct 11       7716     686        105.0      34.0          0.153061   \n1   Sun, Oct 12       9288     785        116.0      91.0          0.147771   \n2   Mon, Oct 13      10480     884        145.0      79.0          0.164027   \n3   Tue, Oct 14       9867     827        138.0      92.0          0.166868   \n4   Wed, Oct 15       9793     832        140.0      94.0          0.168269   \n5   Thu, Oct 16       9500     788        129.0      61.0          0.163706   \n6   Fri, Oct 17       9088     780        127.0      44.0          0.162821   \n7   Sat, Oct 18       7664     652         94.0      62.0          0.144172   \n8   Sun, Oct 19       8434     697        120.0      77.0          0.172166   \n9   Mon, Oct 20      10496     860        153.0      98.0          0.177907   \n10  Tue, Oct 21      10551     864        143.0      71.0          0.165509   \n11  Wed, Oct 22       9737     801        128.0      70.0          0.159800   \n12  Thu, Oct 23       8176     642        122.0      68.0          0.190031   \n13  Fri, Oct 24       9402     697        194.0      94.0          0.278336   \n14  Sat, Oct 25       8669     669        127.0      81.0          0.189836   \n15  Sun, Oct 26       8881     693        153.0     101.0          0.220779   \n16  Mon, Oct 27       9655     771        213.0     119.0          0.276265   \n17  Tue, Oct 28       9396     736        162.0     120.0          0.220109   \n18  Wed, Oct 29       9262     727        201.0      96.0          0.276479   \n19  Thu, Oct 30       9308     728        207.0      67.0          0.284341   \n20  Fri, Oct 31       8715     722        182.0     123.0          0.252078   \n21   Sat, Nov 1       8448     695        142.0     100.0          0.204317   \n22   Sun, Nov 2       8836     724        182.0     103.0          0.251381   \n23   Mon, Nov 3       9359     789          NaN       NaN               NaN   \n24   Tue, Nov 4       9427     743          NaN       NaN               NaN   \n25   Wed, Nov 5       9633     808          NaN       NaN               NaN   \n26   Thu, Nov 6       9842     831          NaN       NaN               NaN   \n27   Fri, Nov 7       9272     767          NaN       NaN               NaN   \n28   Sat, Nov 8       8969     760          NaN       NaN               NaN   \n29   Sun, Nov 9       9697     850          NaN       NaN               NaN   \n30  Mon, Nov 10      10445     851          NaN       NaN               NaN   \n31  Tue, Nov 11       9931     831          NaN       NaN               NaN   \n32  Wed, Nov 12      10042     802          NaN       NaN               NaN   \n33  Thu, Nov 13       9721     829          NaN       NaN               NaN   \n34  Fri, Nov 14       9304     770          NaN       NaN               NaN   \n35  Sat, Nov 15       8668     724          NaN       NaN               NaN   \n36  Sun, Nov 16       8988     710          NaN       NaN               NaN   \n\n    Net conversion  \n0         0.049563  \n1         0.115924  \n2         0.089367  \n3         0.111245  \n4         0.112981  \n5         0.077411  \n6         0.056410  \n7         0.095092  \n8         0.110473  \n9         0.113953  \n10        0.082176  \n11        0.087391  \n12        0.105919  \n13        0.134864  \n14        0.121076  \n15        0.145743  \n16        0.154345  \n17        0.163043  \n18        0.132050  \n19        0.092033  \n20        0.170360  \n21        0.143885  \n22        0.142265  \n23             NaN  \n24             NaN  \n25             NaN  \n26             NaN  \n27             NaN  \n28             NaN  \n29             NaN  \n30             NaN  \n31             NaN  \n32             NaN  \n33             NaN  \n34             NaN  \n35             NaN  \n36             NaN  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Pageviews</th>\n      <th>Clicks</th>\n      <th>Enrollments</th>\n      <th>Payments</th>\n      <th>Gross conversion</th>\n      <th>Net conversion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sat, Oct 11</td>\n      <td>7716</td>\n      <td>686</td>\n      <td>105.0</td>\n      <td>34.0</td>\n      <td>0.153061</td>\n      <td>0.049563</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sun, Oct 12</td>\n      <td>9288</td>\n      <td>785</td>\n      <td>116.0</td>\n      <td>91.0</td>\n      <td>0.147771</td>\n      <td>0.115924</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mon, Oct 13</td>\n      <td>10480</td>\n      <td>884</td>\n      <td>145.0</td>\n      <td>79.0</td>\n      <td>0.164027</td>\n      <td>0.089367</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tue, Oct 14</td>\n      <td>9867</td>\n      <td>827</td>\n      <td>138.0</td>\n      <td>92.0</td>\n      <td>0.166868</td>\n      <td>0.111245</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wed, Oct 15</td>\n      <td>9793</td>\n      <td>832</td>\n      <td>140.0</td>\n      <td>94.0</td>\n      <td>0.168269</td>\n      <td>0.112981</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Thu, Oct 16</td>\n      <td>9500</td>\n      <td>788</td>\n      <td>129.0</td>\n      <td>61.0</td>\n      <td>0.163706</td>\n      <td>0.077411</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Fri, Oct 17</td>\n      <td>9088</td>\n      <td>780</td>\n      <td>127.0</td>\n      <td>44.0</td>\n      <td>0.162821</td>\n      <td>0.056410</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sat, Oct 18</td>\n      <td>7664</td>\n      <td>652</td>\n      <td>94.0</td>\n      <td>62.0</td>\n      <td>0.144172</td>\n      <td>0.095092</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sun, Oct 19</td>\n      <td>8434</td>\n      <td>697</td>\n      <td>120.0</td>\n      <td>77.0</td>\n      <td>0.172166</td>\n      <td>0.110473</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Mon, Oct 20</td>\n      <td>10496</td>\n      <td>860</td>\n      <td>153.0</td>\n      <td>98.0</td>\n      <td>0.177907</td>\n      <td>0.113953</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Tue, Oct 21</td>\n      <td>10551</td>\n      <td>864</td>\n      <td>143.0</td>\n      <td>71.0</td>\n      <td>0.165509</td>\n      <td>0.082176</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Wed, Oct 22</td>\n      <td>9737</td>\n      <td>801</td>\n      <td>128.0</td>\n      <td>70.0</td>\n      <td>0.159800</td>\n      <td>0.087391</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Thu, Oct 23</td>\n      <td>8176</td>\n      <td>642</td>\n      <td>122.0</td>\n      <td>68.0</td>\n      <td>0.190031</td>\n      <td>0.105919</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Fri, Oct 24</td>\n      <td>9402</td>\n      <td>697</td>\n      <td>194.0</td>\n      <td>94.0</td>\n      <td>0.278336</td>\n      <td>0.134864</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sat, Oct 25</td>\n      <td>8669</td>\n      <td>669</td>\n      <td>127.0</td>\n      <td>81.0</td>\n      <td>0.189836</td>\n      <td>0.121076</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Sun, Oct 26</td>\n      <td>8881</td>\n      <td>693</td>\n      <td>153.0</td>\n      <td>101.0</td>\n      <td>0.220779</td>\n      <td>0.145743</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Mon, Oct 27</td>\n      <td>9655</td>\n      <td>771</td>\n      <td>213.0</td>\n      <td>119.0</td>\n      <td>0.276265</td>\n      <td>0.154345</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Tue, Oct 28</td>\n      <td>9396</td>\n      <td>736</td>\n      <td>162.0</td>\n      <td>120.0</td>\n      <td>0.220109</td>\n      <td>0.163043</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Wed, Oct 29</td>\n      <td>9262</td>\n      <td>727</td>\n      <td>201.0</td>\n      <td>96.0</td>\n      <td>0.276479</td>\n      <td>0.132050</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Thu, Oct 30</td>\n      <td>9308</td>\n      <td>728</td>\n      <td>207.0</td>\n      <td>67.0</td>\n      <td>0.284341</td>\n      <td>0.092033</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Fri, Oct 31</td>\n      <td>8715</td>\n      <td>722</td>\n      <td>182.0</td>\n      <td>123.0</td>\n      <td>0.252078</td>\n      <td>0.170360</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Sat, Nov 1</td>\n      <td>8448</td>\n      <td>695</td>\n      <td>142.0</td>\n      <td>100.0</td>\n      <td>0.204317</td>\n      <td>0.143885</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Sun, Nov 2</td>\n      <td>8836</td>\n      <td>724</td>\n      <td>182.0</td>\n      <td>103.0</td>\n      <td>0.251381</td>\n      <td>0.142265</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Mon, Nov 3</td>\n      <td>9359</td>\n      <td>789</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Tue, Nov 4</td>\n      <td>9427</td>\n      <td>743</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Wed, Nov 5</td>\n      <td>9633</td>\n      <td>808</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Thu, Nov 6</td>\n      <td>9842</td>\n      <td>831</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Fri, Nov 7</td>\n      <td>9272</td>\n      <td>767</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Sat, Nov 8</td>\n      <td>8969</td>\n      <td>760</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Sun, Nov 9</td>\n      <td>9697</td>\n      <td>850</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Mon, Nov 10</td>\n      <td>10445</td>\n      <td>851</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Tue, Nov 11</td>\n      <td>9931</td>\n      <td>831</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Wed, Nov 12</td>\n      <td>10042</td>\n      <td>802</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Thu, Nov 13</td>\n      <td>9721</td>\n      <td>829</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Fri, Nov 14</td>\n      <td>9304</td>\n      <td>770</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Sat, Nov 15</td>\n      <td>8668</td>\n      <td>724</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Sun, Nov 16</td>\n      <td>8988</td>\n      <td>710</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#The total number of days that we have available data\n\ncontrol_data['Gross conversion'].count()",
            "execution_count": 53,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 53,
                    "data": {
                        "text/plain": "23"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "(control_data['Gross conversion']>experiment_data['Gross conversion']).value_counts()",
            "execution_count": 55,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 55,
                    "data": {
                        "text/plain": "True     19\nFalse    18\nName: Gross conversion, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "(control_data['Net conversion']>experiment_data['Net conversion']).value_counts()",
            "execution_count": 56,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 56,
                    "data": {
                        "text/plain": "False    24\nTrue     13\nName: Net conversion, dtype: int64"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "_Sign test calculation can be achieved by using [online calculator](https://www.graphpad.com/quickcalcs/binomial1.cfm)_\n\n_Gross conversion:\nThere are 19 of 23 days that the control group has a higher gross conversion value than the experiment group.\nThe two-tailed p-value for 19 of 23 successes is 0.0026. That p-value is significant at alpha at 0.05 level._\n\n_Net conversion:\nThe two-tailed p-value for 13 of 23 successes is 0.6776. That p-value is not significant at alpha at 0.05 level._\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### 3.2.3 Summary\n\n_Effect size tests and sign tests showed gross conversion change would be both statistically and practically significantly reduced if we change the website. But the change for net conversion was not statistically significant._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3.3 Recommendation\nMake a recommendation and briefly describe your reasoning.\n\n_The purpose of this experiment is to reduce the number of frustrated students who left the free trial because they didn't have enough time. The results showed that the gross conversion was both significantly and practically decreased in the experiment group. The change we made to the website screened out some students who may potentially drop the class during the free trial. The net conversion was not significantly changed, so the new change to the website didn't significantly reduce the number of students to continue past the free trial and eventually complete the course as requested by experiment purpose. Based on the above results, I decided to launch the change._"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 4. Follow-Up Experiment\n\n_A follow-up experiment could be run to investigate the number of user-ids to complete the course divided by the number of unique cookies to click the \"Start free trial\" button. The students who do not have enough time to engage in the course may still stay after 14-day trials, because the first one or two chapters of the course may only include background and introductions, and seem not very time-consuming. Once they dig deeper into the course, it may take them more time to finish the homework, pass the quiz and complete the final project. If the students didn't get prepared to spend enough time on the course, they may not complete the course even after they stayed after the 14-day trial and paid for the course. If that's the case, they will be even more frustrated because they paid money but could not catch up with the progress. In the experiment group, students already know how much time they are going to spend on the course, then it is less likely that they paid and failed to finish the course._"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}